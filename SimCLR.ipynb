{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "frank-perry",
   "metadata": {},
   "source": [
    "# SimCLR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-lawyer",
   "metadata": {},
   "source": [
    "<img src=\"img/SimCLR.png\" width=\"30%\">  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "young-production",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "import os\n",
    "import PIL.Image as Image\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os import walk\n",
    "import glob\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "import simsiam.loader\n",
    "\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from PIL import Image, ImageFilter\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torchvision.models as models\n",
    "from facenet_pytorch import InceptionResnetV1\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from sync_batchnorm import convert_model\n",
    "from pytorch_metric_learning.losses import NTXentLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wanted-return",
   "metadata": {},
   "source": [
    "## GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-zoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH_TRAIN = '../../dataset/face_labeled_data/train'\n",
    "DATA_PATH_VAL = '../../dataset/face_labeled_data/val'\n",
    "batch_size = 256\n",
    "# learning rate\n",
    "# init_learning_rate = 0.05 * batch_size / 256\n",
    "init_learning_rate = 0.005 * batch_size / 256\n",
    "momentum_val = 0.9\n",
    "weight_decay_val = 1e-4\n",
    "output_foloder = 'model_simCLR_lin'\n",
    "WORKERS = 16\n",
    "\n",
    "print('torch version:' + torch.__version__)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('Available GPUs: ', end='')\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(torch.cuda.get_device_name(i), end=' ')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('CUDA is not available.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acceptable-symposium",
   "metadata": {},
   "source": [
    "## define dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-locator",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceImages(Dataset):\n",
    "    \n",
    "    def __init__(self, img_dir, transform, specific = '**'):\n",
    "        self.img_dir = img_dir\n",
    "        self.img_path_list = glob.glob(os.path.join(img_dir, specific + '/*.jpg'))\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_path_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_path_list[idx]\n",
    "        img = FaceImages.read_image(img_path)\n",
    "        target = int(img_path.split('/')[5])\n",
    "        return self.transform(img), self.transform(img), target\n",
    "    \n",
    "    @staticmethod\n",
    "    def read_image(img_path):\n",
    "        #return cv2.imread(img_path)\n",
    "        return Image.open(img_path, mode='r').convert('RGB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-watts",
   "metadata": {},
   "source": [
    "## define data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-endorsement",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "                          \n",
    "def get_aug_trnsform(s=1.0):\n",
    "    color_jitter = transforms.ColorJitter(0.8*s, 0.8*s, 0.8*s, 0.1)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(80, scale=(0.2, 1.)),\n",
    "        transforms.RandomApply([\n",
    "            transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)  # not strengthened\n",
    "        ], p=0.8),\n",
    "        transforms.RandomGrayscale(p=0.2),\n",
    "        transforms.RandomApply([simsiam.loader.GaussianBlur([.1, 2.])], p=0.5),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "    \n",
    "    return transform\n",
    "\n",
    "def ge_eval_trnsform(s=1.0):\n",
    "    color_jitter = transforms.ColorJitter(0.8*s, 0.8*s, 0.8*s, 0.1)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "    \n",
    "    return transform\n",
    "\n",
    "aug = get_aug_trnsform(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-speaker",
   "metadata": {},
   "source": [
    "## define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specified-bangkok",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make embedding to length=1\n",
    "class L2_norm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(L2_norm, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.normalize(x, p=2, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "english-communist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder\n",
    "encoder = InceptionResnetV1()\n",
    "# projector\n",
    "projector = nn.Sequential(\n",
    "    nn.Linear(512, 512)\n",
    ") \n",
    "encoder = nn.DataParallel(encoder)\n",
    "# after convert, m is using SyncBN\n",
    "encoder = convert_model(encoder)\n",
    "\n",
    "projector = nn.DataParallel(projector)\n",
    "# after convert, m is using SyncBN\n",
    "projector = convert_model(projector)\n",
    "\n",
    "encoder.to(device)\n",
    "projector.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-imperial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "from torch import optim\n",
    "optim_params_encoder = [{'params': encoder.parameters(), 'fix_lr': False}]\n",
    "optim_params_projector = [{'params': projector.parameters(), 'fix_lr': False}]\n",
    "\n",
    "encoder_opt = optim.SGD(optim_params_encoder, lr=init_learning_rate, momentum = momentum_val, weight_decay = weight_decay_val)\n",
    "projector_opt = optim.SGD(optim_params_projector, lr=init_learning_rate, momentum = momentum_val, weight_decay = weight_decay_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-counter",
   "metadata": {},
   "source": [
    "### save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-experience",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-cheat",
   "metadata": {},
   "source": [
    "### 動態lr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-threat",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, init_lr, epoch, epochs):\n",
    "    \"\"\"Decay the learning rate based on schedule\"\"\"\n",
    "    cur_lr = init_lr * 0.5 * (1. + math.cos(math.pi * epoch / epochs))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        if 'fix_lr' in param_group and param_group['fix_lr']:\n",
    "            param_group['lr'] = init_lr\n",
    "        else:\n",
    "            param_group['lr'] = cur_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaging-instrumentation",
   "metadata": {},
   "source": [
    "### define loss_fnc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-timeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = NTXentLoss(temperature=0.10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stone-survey",
   "metadata": {},
   "source": [
    "### define accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-friday",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-algeria",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-slave",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pass_epoch(loader, mode = 'Train'):\n",
    "    loss = 0\n",
    "    loss_sim = 0\n",
    "    loss_var = 0\n",
    "    loss_cov = 0\n",
    "    if (mode == 'Train'):\n",
    "        encoder.train()\n",
    "        projector.train()\n",
    "    else:\n",
    "        encoder.eval()\n",
    "        projector.eval()\n",
    "    for i_batch, image_batch in tqdm(enumerate(loader)):\n",
    "        target  = torch.stack(list(image_batch[2]), dim=0).to(device)\n",
    "        x1, x2 = image_batch[0].to(device), image_batch[1].to(device)\n",
    "        # forward\n",
    "        y1, y2 = encoder(x1), encoder(x2)\n",
    "        z1, z2 = projector(y1), projector(y2)\n",
    "\n",
    "        # compute loos\n",
    "        embeddings = torch.cat((z1, z2))\n",
    "        indices = torch.arange(0, z1.size(0), device=z1.device)\n",
    "        labels = torch.cat((indices, indices))\n",
    "        loss_batch = loss_func(embeddings, labels)\n",
    "        \n",
    "        loss += loss_batch\n",
    "\n",
    "        if mode == 'Train':\n",
    "            # update\n",
    "            encoder_opt.zero_grad()\n",
    "            projector_opt.zero_grad()\n",
    "            loss_batch.backward()\n",
    "            encoder_opt.step()\n",
    "            projector_opt.step()        \n",
    "    return loss / (i_batch + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-salad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm \n",
    "\n",
    "dataset_train = FaceImages(DATA_PATH_TRAIN, aug)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, num_workers=WORKERS, shuffle=True)\n",
    "dataset_val = FaceImages(DATA_PATH_VAL, aug)\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=batch_size, num_workers=WORKERS, shuffle=True)\n",
    "\n",
    "epoch = 100\n",
    "\n",
    "loss_history_train = []\n",
    "loss_history_val = []\n",
    "\n",
    "def update_loss_hist(train_list, val_list, name='result'):\n",
    "    clear_output(wait=True)\n",
    "    plt.plot(train_list)\n",
    "    plt.plot(val_list)\n",
    "    plt.title(name)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'val'], loc='center right')\n",
    "    plt.savefig('./{}/{}.png'.format(output_foloder, name))\n",
    "    plt.show()\n",
    "\n",
    "# train loop\n",
    "for i in range(epoch):\n",
    "    adjust_learning_rate(encoder_opt, init_learning_rate, i, epoch)\n",
    "    adjust_learning_rate(projector_opt, init_learning_rate, i, epoch)\n",
    "    \n",
    "    train_loss = pass_epoch(dataloader_train, 'Train')\n",
    "    with torch.no_grad():\n",
    "        val_loss = pass_epoch(dataloader_val, 'Eval')\n",
    "\n",
    "    \n",
    "    loss_history_train.append(train_loss)\n",
    "    loss_history_val.append(val_loss)\n",
    "    update_loss_hist(loss_history_train, loss_history_val, 'NTXentLoss')\n",
    "\n",
    "    save_checkpoint({\n",
    "        'epoch': i + 1,\n",
    "        'arch': 'SimCLR',\n",
    "        'state_dict': encoder.state_dict(),\n",
    "        'optimizer' : encoder.state_dict(),\n",
    "    }, is_best=False, filename='./{}/checkpoint_{:04d}.pth.tar'.format(output_foloder, i + 1))\n",
    "torch.save(encoder, './{}/checkpoint.pth.tar'.format(output_foloder))\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weekly-secret",
   "metadata": {},
   "source": [
    "### collapse check(simularity matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-campbell",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = './{}/checkpoint.pth.tar'.format(output_foloder)\n",
    "model = torch.load(MODEL_PATH).to(device).eval()\n",
    "\n",
    "dataset_eval = FaceImages(DATA_PATH_VAL, ge_eval_trnsform(0.5))\n",
    "dataloader_eval = DataLoader(dataset_eval, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "def collapseCheck(model, loader):\n",
    "    x, _, _ = next(iter(loader))\n",
    "    h = model(x.to(device))\n",
    "    h_norm = h / h.norm(dim=1)[:, None]\n",
    "    res = torch.mm(h_norm, h_norm.transpose(0,1))\n",
    "    print(res.cpu().detach().numpy())\n",
    "    \n",
    "collapseCheck(model, dataloader_eval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
