{
 "cells": [
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "portuguese-tribe",
=======
   "id": "driven-refund",
>>>>>>> 42938e1f0b653604946507663488f1cf44819e7d
   "metadata": {},
   "source": [
    "# 單純只使用simsiam \n",
    "## embedding判斷人臉"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "coral-lobby",
=======
   "id": "narrative-fields",
>>>>>>> 42938e1f0b653604946507663488f1cf44819e7d
   "metadata": {},
   "source": [
    "### import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "juvenile-cyprus",
=======
   "id": "spoken-quest",
>>>>>>> 42938e1f0b653604946507663488f1cf44819e7d
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "from os import listdir\n",
    "from os import walk\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1, fixed_image_standardization\n",
    "import PIL.Image as Image\n",
    "from matplotlib import pyplot as plt\n",
    "import simsiam.loader\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from tqdm import tqdm \n",
    "from IPython.display import clear_output\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import DataParallel\n",
    "from sync_batchnorm import SynchronizedBatchNorm1d,  patch_replication_callback"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "fixed-hartford",
=======
   "id": "disabled-humor",
>>>>>>> 42938e1f0b653604946507663488f1cf44819e7d
   "metadata": {},
   "source": [
    "### check gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "existing-liberal",
=======
   "id": "accompanied-instruction",
>>>>>>> 42938e1f0b653604946507663488f1cf44819e7d
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH_TRAIN = '../../dataset/face_labeled_data/train'\n",
    "DATA_PATH_VAL = '../../dataset/face_labeled_data/val'\n",
    "DATA_PATH_TEST = '../../dataset/face_labeled_data/test'\n",
    "DATA_PATH_NEVER = '../../dataset/face_labeled_data/never_seen'\n",
    "\n",
    "# MODEL_PATH = \"./model_facenet_simsiam/checkpoint_0100.pth.tar\"\n",
    "# MODEL_PATH = \"./model_featureExtraction_triplet/checkpoint_0100.pth.tar\"\n",
    "MODEL_PATH = \"./model_V2_1024_fix_only_cross/checkpoint.pth.tar\"\n",
    "BATCH_SIZE = 32\n",
    "WORKERS = 8\n",
    "\n",
    "print('torch version:' + torch.__version__)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('Available GPUs: ', end='')\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(torch.cuda.get_device_name(i), end=' ')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('CUDA is not available.')"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "metallic-extreme",
=======
   "id": "fabulous-printing",
>>>>>>> 42938e1f0b653604946507663488f1cf44819e7d
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "driving-stupid",
=======
   "id": "ecological-warrant",
>>>>>>> 42938e1f0b653604946507663488f1cf44819e7d
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "                          \n",
    "def get_aug_trnsform(s=1.0):\n",
    "    color_jitter = transforms.ColorJitter(0.8*s, 0.8*s, 0.8*s, 0.1)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224, scale=(0.2, 1.)),\n",
    "        transforms.RandomApply([\n",
    "            transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)  # not strengthened\n",
    "        ], p=0.8),\n",
    "        transforms.RandomGrayscale(p=0.2),\n",
    "        transforms.RandomApply([simsiam.loader.GaussianBlur([.1, 2.])], p=0.5),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "    \n",
    "    return transform\n",
    "\n",
    "def ge_eval_trnsform(s=1.0):\n",
    "    color_jitter = transforms.ColorJitter(0.8*s, 0.8*s, 0.8*s, 0.1)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "    \n",
    "    return transform\n",
    "\n",
    "trans_aug = get_aug_trnsform(0.5)\n",
    "trans_eval = get_aug_trnsform(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "compatible-insider",
=======
   "id": "civic-strategy",
>>>>>>> 42938e1f0b653604946507663488f1cf44819e7d
   "metadata": {},
   "source": [
    "#### Define dataset, and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "universal-frame",
=======
   "id": "legislative-directive",
>>>>>>> 42938e1f0b653604946507663488f1cf44819e7d
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceImages(Dataset):\n",
    "    \n",
    "    def __init__(self, img_dir, transform, specific = '**'):\n",
    "        self.img_dir = img_dir\n",
    "        self.img_path_list = glob.glob(os.path.join(img_dir, specific + '/*.jpg'))\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_path_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_path_list[idx]\n",
    "        img = FaceImages.read_image(img_path)\n",
    "        target = img_path.split('/')[5]\n",
    "        return self.transform(img), self.transform(img), target\n",
    "    \n",
    "    @staticmethod\n",
    "    def read_image(img_path):\n",
    "        #return cv2.imread(img_path)\n",
    "        return Image.open(img_path, mode='r').convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "australian-harrison",
=======
   "id": "prospective-commander",
>>>>>>> 42938e1f0b653604946507663488f1cf44819e7d
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_train = FaceImages(DATA_PATH_TRAIN, transform=trans_aug)\n",
    "# dataset_val = FaceImages(DATA_PATH_VAL, transform=trans_eval)\n",
    "# dataset_test = FaceImages(DATA_PATH_TEST, transform=trans_eval)\n",
    "\n",
    "trans = transforms.Compose([\n",
    "    np.float32,\n",
    "    transforms.ToTensor(),\n",
    "    fixed_image_standardization\n",
    "])\n",
    "\n",
    "dataset_train = datasets.ImageFolder(DATA_PATH_TRAIN, transform=trans)\n",
    "dataset_val = datasets.ImageFolder(DATA_PATH_VAL, transform=trans)\n",
    "dataset_test = datasets.ImageFolder(DATA_PATH_TEST, transform=trans)\n",
    "dataset_never = datasets.ImageFolder(DATA_PATH_NEVER, transform=trans)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset_train,\n",
    "    num_workers=WORKERS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset_val,\n",
    "    num_workers=WORKERS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset_test,\n",
    "    num_workers=WORKERS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "never_loader = DataLoader(\n",
    "    dataset_never,\n",
    "    num_workers=WORKERS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "for i in np.unique(dataset_never.targets):\n",
    "    print(i, \", \", dataset_never.targets.count(i))"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "desirable-listening",
=======
   "id": "controversial-impossible",
>>>>>>> 42938e1f0b653604946507663488f1cf44819e7d
   "metadata": {},
   "source": [
    "### load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "federal-calvin",
=======
   "id": "skilled-speaker",
>>>>>>> 42938e1f0b653604946507663488f1cf44819e7d
   "metadata": {},
   "outputs": [],
   "source": [
    "# make embedding to length=1\n",
    "class L2_norm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(L2_norm, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.normalize(x, p=2, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "possible-decrease",
=======
   "id": "impaired-radio",
>>>>>>> 42938e1f0b653604946507663488f1cf44819e7d
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadEvalModel(model_path):\n",
    "#     backbone = InceptionResnetV1()\n",
    "#     projector = nn.Sequential(\n",
    "#     nn.Linear(512, 2048), nn.BatchNorm1d(2048), nn.ReLU(),\n",
    "#     nn.Linear(2048, 2048), nn.BatchNorm1d(2048), nn.ReLU(),\n",
    "#     nn.Linear(2048, 512), L2_norm()\n",
    "#     ) \n",
    "#     projector = nn.Sequential(\n",
    "#         nn.Linear(512, 1024), nn.BatchNorm1d(1024), nn.ReLU(),\n",
    "#         nn.Linear(1024, 1024), nn.BatchNorm1d(1024), nn.ReLU(),\n",
    "#         nn.Linear(1024, 512), L2_norm()\n",
    "#     ) \n",
    "#     model = nn.Sequential(\n",
    "#     backbone,\n",
    "#     projector\n",
    "#     )\n",
    "#     model = InceptionResnetV1()\n",
    "#     model.load_state_dict(torch.load(model_path)['state_dict'])\n",
    "    model = torch.load(MODEL_PATH)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "atmospheric-brazil",
=======
   "id": "disciplinary-charlotte",
>>>>>>> 42938e1f0b653604946507663488f1cf44819e7d
   "metadata": {},
   "source": [
    "### collapse check(simularity matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "comparative-celtic",
=======
   "id": "mexican-strain",
>>>>>>> 42938e1f0b653604946507663488f1cf44819e7d
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapseCheck(model, loader):\n",
    "    x, _ = next(iter(loader))\n",
    "    h = model(x.to(device))\n",
    "    h_norm = h / h.norm(dim=1)[:, None]\n",
    "    res = torch.mm(h_norm, h_norm.transpose(0,1))\n",
    "    print(res.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "apart-bristol",
=======
   "id": "polar-butter",
>>>>>>> 42938e1f0b653604946507663488f1cf44819e7d
   "metadata": {},
   "source": [
    "### validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "relevant-absolute",
=======
   "id": "welsh-calendar",
>>>>>>> 42938e1f0b653604946507663488f1cf44819e7d
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(data_loader, model, l2 = False):\n",
    "    y_pre_list = []\n",
    "    y_list = []    \n",
    "    for i_batch, image_batch in tqdm(enumerate(data_loader)):\n",
    "        x = image_batch[0].to(device)\n",
    "        y = image_batch[1]\n",
    "        if (l2):\n",
    "            model = nn.Sequential(model, L2_norm())\n",
    "        y_pre = model(x)\n",
    "        y_pre = y_pre.cpu().detach().numpy()\n",
    "        for j, data in enumerate(y_pre):\n",
    "            y_pre_list.append(data)\n",
    "            y_list.append(int(y[j]))\n",
    "    return y_pre_list, y_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "photographic-murray",
=======
   "id": "engaged-butler",
>>>>>>> 42938e1f0b653604946507663488f1cf44819e7d
   "metadata": {},
   "outputs": [],
   "source": [
    "size=dataset_never.__len__()\n",
    "print('val data size = ', size)"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "architectural-district",
=======
   "id": "educated-allowance",
>>>>>>> 42938e1f0b653604946507663488f1cf44819e7d
   "metadata": {},
   "source": [
    "### 計算兩embeddings之距離\n",
    "distance_metric = 0 歐幾里得距離  (Euclidean distance)  \n",
    "distance_metric = 1 餘弦相似性 (Cosine similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "foster-cosmetic",
=======
   "id": "continental-michael",
>>>>>>> 42938e1f0b653604946507663488f1cf44819e7d
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(embeddings1, embeddings2, distance_metric=0):\n",
    "    if distance_metric==0:\n",
    "        # Euclidean distance\n",
    "        diff = np.subtract(embeddings1, embeddings2)\n",
    "        dist = np.sum(np.square(diff),0)\n",
    "    elif distance_metric==1:\n",
    "        # Distance based on cosine similarity\n",
    "        dot = np.sum(np.multiply(embeddings1, embeddings2), axis=0)\n",
    "        norm = np.linalg.norm(embeddings1, axis=0) * np.linalg.norm(embeddings2, axis=0)\n",
    "        similarity = dot / norm\n",
    "        dist = np.arccos(similarity) / math.pi\n",
    "    else:\n",
    "        raise 'Undefined distance metric %d' % distance_metric \n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "opened-grade",
=======
   "id": "noticed-western",
>>>>>>> 42938e1f0b653604946507663488f1cf44819e7d
   "metadata": {},
   "source": [
    "### 計算Cluste  離散度\n",
    "1.根據target分群  \n",
    "2.計算每一群中心點  \n",
    "3.每一群的所有點對中心點計算歐式距離  \n",
    "4.上步驟所有距離取平均  \n",
    "5.所有群的平均距離再取平均  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "vertical-belle",
=======
   "id": "blocked-toolbox",
>>>>>>> 42938e1f0b653604946507663488f1cf44819e7d
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateClusterDistance(y_pre, target):\n",
    "    dist = []\n",
    "    y_new = np.array(y_pre)\n",
    "    for index, target_str in enumerate(np.unique(target)):\n",
    "        cluster_dist = 0\n",
    "        data = y_new[[x for x, y in list(enumerate(target))if y == target_str]]\n",
    "        meanPoint = np.mean(data, axis=0)\n",
    "        for embedding in data:\n",
    "            cluster_dist += distance(embedding, meanPoint)\n",
    "        dist.append(cluster_dist / len(data))\n",
    "    return np.mean(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "preceding-valentine",
=======
   "id": "beginning-trader",
>>>>>>> 42938e1f0b653604946507663488f1cf44819e7d
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateClusterVAL(y_pre, target, d = 1):\n",
    "    ta = []\n",
    "    y_new = np.array(y_pre)\n",
    "    for index, target_str in tqdm(enumerate(np.unique(target))):\n",
    "        data = y_new[[x for x, y in list(enumerate(target))if y == target_str]]\n",
    "        count = 0\n",
    "        ta_count = 0\n",
    "        if len(data) <= 1:\n",
    "            continue\n",
    "        for i in range(len(data) - 1):\n",
    "            for j in range(i + 1, len(data)):\n",
    "                count+=1\n",
    "                if distance(data[i], data[j]) <= d:\n",
    "                    ta_count+=1\n",
    "        ta.append(ta_count / count)\n",
    "    return np.mean(ta)\n",
    "def calculateClusterFAR(y_pre, target, d = 1):\n",
    "    fa = []\n",
    "    y_new = np.array(y_pre)\n",
    "    for index, target_str in tqdm(enumerate(np.unique(target))):\n",
    "        data = y_new[[x for x, y in list(enumerate(target))if y == target_str]]\n",
    "        other_data = y_new[[x for x, y in list(enumerate(target))if y != target_str]]\n",
    "        count = 0\n",
    "        fa_count = 0\n",
    "        if len(data) <= 1:\n",
    "            continue\n",
    "        for i in range(len(data)):\n",
    "            for j in range(len(other_data)):\n",
    "                count+=1\n",
    "                if distance(data[i], other_data[j]) <= d:\n",
    "                    fa_count+=1\n",
    "        fa.append(fa_count / count)\n",
    "    return np.mean(fa)\n",
    "\n",
    "def calculateClusterVAL_FAR(y_pre, target, val_d, far_d):\n",
    "    y_new = np.array(y_pre)\n",
    "    ta_count = 0\n",
    "    ta_count_true = 0\n",
    "    fa_count = 0\n",
    "    fa_count_true = 0\n",
    "    for i in range(len(y_new) - 1):\n",
    "        for j in range(i, len(y_new)):\n",
    "            dist = distance(y_new[i], y_new[j])\n",
    "            if target[i] == target[j]:\n",
    "                ta_count += 1\n",
    "                if dist <= val_d:\n",
    "                    ta_count_true += 1\n",
    "            else:\n",
    "                fa_count += 1\n",
    "                if dist <= far_d:\n",
    "                    fa_count_true +=1\n",
    "    return ta_count_true / ta_count, fa_count_true / fa_count"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "fantastic-newfoundland",
=======
   "id": "broke-punishment",
>>>>>>> 42938e1f0b653604946507663488f1cf44819e7d
   "metadata": {},
   "source": [
    "### Acc公式\n",
    "對每一筆data找k個最近的data 看有多少是相同的class\n",
    "\n",
    "### TA 公式\n",
    "<img src=\"img/TA.png\" width=\"50%\">  \n",
    "\n",
    "### FA 公式\n",
    "<img src=\"img/FA.png\" width=\"50%\">  \n",
    "\n",
    "### VAL FAR\n",
    "<img src=\"img/VAL_FAR.png\" width=\"50%\"> "
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "proof-suspension",
=======
   "id": "immune-individual",
>>>>>>> 42938e1f0b653604946507663488f1cf44819e7d
   "metadata": {},
   "source": [
    "### gpu 算距離"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "antique-honolulu",
=======
   "id": "chicken-newark",
>>>>>>> 42938e1f0b653604946507663488f1cf44819e7d
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdist(v):\n",
    "    dist = torch.norm(v[:, None] - v, dim=2, p=2)\n",
    "    return dist\n",
    "\n",
    "def makemask(targets):\n",
    "    n = targets.shape[0]\n",
    "    # find the hardest positive and negative\n",
    "    mask_pos = targets.expand(n, n).eq(targets.expand(n, n).t())\n",
    "    mask_neg = ~mask_pos\n",
    "    mask_pos[torch.eye(n).byte().to(device)] = 0\n",
    "    return mask_pos, mask_neg\n",
    "\n",
    "def calculateClusterVAL_FAR_GPU(y_pre, target, val_d = 1., far_d = 1.):\n",
    "    dist = pdist(torch.Tensor(y_pre).cpu())\n",
    "    mask_pos, mask_neg = makemask(torch.Tensor(target).cpu())\n",
    "    \n",
    "#     print(dist)\n",
    "    dist[dist == 0] = float('nan')\n",
    "    \n",
    "    pos = dist * mask_pos.float()\n",
    "#     print('pos pre', pos)\n",
    "    pos[pos == 0] = float('nan')\n",
    "\n",
    "    neg = dist * mask_neg.float()\n",
    "#     print('neg pre', neg)\n",
    "    neg[neg == 0] = float('nan')\n",
    "#     print('mask_pos ', mask_pos)\n",
    "#     print('mask_neg ', mask_neg)\n",
    "#     print('pos ', pos)\n",
    "#     print('neg ', neg)\n",
    "    ta = torch.sum(pos <= far_d)\n",
    "    fa = torch.sum(neg <= far_d)\n",
    "\n",
    "    psame = torch.sum(mask_pos == True)\n",
    "    pdiff = torch.sum(mask_neg == True)\n",
    "    \n",
    "    val = ta / psame\n",
    "    far = fa / pdiff\n",
    "    return val.detach().numpy(), far.detach().numpy()\n",
    "\n",
    "def calculateClusterACC_GPU(y_pre, target, k = 2):\n",
    "    dist = pdist(torch.Tensor(y_pre).cpu())\n",
    "    dist[dist == 0] = float('nan')\n",
    "    mask_pos, mask_neg = makemask(torch.Tensor(target).cpu())\n",
    "#     print(dist)\n",
    "    values, indices = torch.topk(dist, k, largest = False)\n",
    "    \n",
    "#     print(indices)\n",
    "#     print(torch.gather(mask_pos, 1, indices))\n",
    "    acc_count = torch.sum(torch.gather(mask_pos, 1, indices) == True, 1) / k\n",
    "    acc = acc_count / k\n",
    "    return acc.detach().numpy().mean()\n",
    "\n",
    "def calculateClusterDistClose_GPU(y_pre, target):\n",
    "    dist = pdist(torch.Tensor(y_pre).cpu())\n",
    "    mask_pos, mask_neg = makemask(torch.Tensor(target).cpu())    \n",
    "#     print(dist)\n",
    "    dist[dist == 0] = float('nan')\n",
    "    pos = dist * mask_pos.float()\n",
    "#     print('pos pre', pos)\n",
    "    pos[pos == 0] = float('nan')\n",
    "    neg = dist * mask_neg.float()\n",
    "#     print('neg pre', neg)\n",
    "    neg[neg == 0] = float('nan')\n",
    "#     print('mask_pos ', mask_pos)\n",
    "#     print('mask_neg ', mask_neg)\n",
    "#     print('pos ', pos)\n",
    "#     print('neg ', neg)\n",
    "    sameD_val = torch.nansum(pos)\n",
    "    diffD_val = torch.nansum(neg)\n",
    "\n",
    "    psame = torch.sum(mask_pos == True)\n",
    "    pdiff = torch.sum(mask_neg == True)\n",
    "    \n",
    "#     print('sameD_val ', sameD_val)\n",
    "#     print('diffD_val ', diffD_val)\n",
    "#     print('psame ', psame)\n",
    "#     print('pdiff ', pdiff)\n",
    "    sameD = sameD_val / psame\n",
    "    diffD = diffD_val / pdiff\n",
    "    return sameD.detach().numpy(), diffD.detach().numpy()\n",
    "\n",
    "# test_y_pre = [[0, 1], [0, 5], [0, 2], [0, 6]]\n",
    "# test_y = [1, 2, 1, 2]\n",
    "\n",
    "# calculateClusterVAL_FAR_GPU(test_y_pre, test_y)\n",
    "# calculateClusterDistClose_GPU(test_y_pre, test_y)\n",
    "#calculateClusterACC_GPU(test_y_pre, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "engaged-beauty",
=======
   "id": "removable-appliance",
>>>>>>> 42938e1f0b653604946507663488f1cf44819e7d
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal(y_pre, y, kMax = 10):\n",
    "    valList = []\n",
    "    farList = []\n",
    "    accList = []\n",
    "    accK = []\n",
    "#     ds = [2, 1.5, 1, 0.5, 10**-1, 10**-2, 10**-3, 10**-4, 10**-5, 10**-6]\n",
    "    for i in tqdm(range(21)):\n",
    "        power = i - 1\n",
    "        val, far = calculateClusterVAL_FAR_GPU(y_pre, y, i / 10, i / 10)\n",
    "        valList.append(val)\n",
    "        farList.append(far)\n",
    "    for k in tqdm(range(1, kMax + 1)):\n",
    "        acc = calculateClusterACC_GPU(y_pre, y, k)\n",
    "        accList.append(acc)\n",
    "        accK.append(k)    \n",
    "    return valList, farList, accList, accK\n",
    "# valList, farList, accList, accK = cal(y_pre, y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "miniature-aruba",
=======
   "id": "identical-italic",
>>>>>>> 42938e1f0b653604946507663488f1cf44819e7d
   "metadata": {},
   "outputs": [],
   "source": [
    "def showVAL_FAR_ACC(valList, farList, accList, accK):\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(6, 10))\n",
    "    plt.title('VAL_FAR')\n",
    "    \n",
    "    axs[1].set_ylim([0,1])\n",
    "    \n",
    "    axs[0].title.set_text('VAL_FAR')\n",
    "    axs[1].title.set_text('acc(k)')\n",
    "\n",
    "    axs[0].set_xlabel('FAR')\n",
    "    axs[0].set_ylabel('VAL')\n",
    "\n",
    "    axs[1].set_xlabel('k')\n",
    "    axs[1].set_ylabel('acc')\n",
    "\n",
    "    # plt.legend(['model'], loc='center right')\n",
    "    axs[0].scatter(farList, valList)\n",
    "    axs[0].plot(farList, valList)\n",
    "    axs[1].scatter(accK, accList)\n",
    "    axs[1].plot(accK, accList)\n",
    "\n",
    "    plt.savefig('ROC_ACC.png')\n",
    "    plt.show()\n",
    "# showVAL_FAR_ACC(valList, farList, accList, accK)"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "binding-airport",
=======
   "id": "intellectual-coral",
>>>>>>> 42938e1f0b653604946507663488f1cf44819e7d
   "metadata": {},
   "source": [
    "### PCA T-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "outdoor-duncan",
=======
   "id": "prescribed-breeding",
>>>>>>> 42938e1f0b653604946507663488f1cf44819e7d
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "def feature2pca(y_pre):\n",
    "    pca = PCA(n_components=2)\n",
    "    return pca.fit_transform(y_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "assisted-indication",
=======
   "id": "fatal-marsh",
>>>>>>> 42938e1f0b653604946507663488f1cf44819e7d
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import manifold\n",
    "def featurn2tsne(y_pre):\n",
    "    return manifold.TSNE(n_components=2, init='random', random_state=5, verbose=0).fit_transform(y_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "middle-decade",
=======
   "id": "hungarian-junior",
>>>>>>> 42938e1f0b653604946507663488f1cf44819e7d
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_cluster(ax, pca_data, target, name):\n",
    "    times = [0 for i in range(len(dataset_never.class_to_idx))]\n",
    "#     plt.legend(dataset_never.class_to_idx.keys(), loc='center right')\n",
    "    ax.set_title(name)\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_xlabel('X')\n",
    "    \n",
    "    scatter = ax.scatter(pca_data[:,0], pca_data[:,1] , c=target, marker='o')#, cmap=cmap)\n",
    "    ax.legend(*scatter.legend_elements(), loc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "eight-fellow",
=======
   "id": "boring-grass",
>>>>>>> 42938e1f0b653604946507663488f1cf44819e7d
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_dimension_reduction(y_pre, y):\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(6, 10))\n",
    "    y_pre_pca = feature2pca(y_pre)\n",
    "    y_pre_tsne = featurn2tsne(y_pre)\n",
    "    draw_cluster(axs[0], y_pre_pca, y, 'PCA')\n",
    "    draw_cluster(axs[1], y_pre_tsne, y, 'T-SNE')\n",
    "    plt.savefig('PCA_TSNE.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "norwegian-poster",
=======
   "id": "progressive-division",
>>>>>>> 42938e1f0b653604946507663488f1cf44819e7d
   "metadata": {},
   "source": [
    "### 一鍵測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "fleet-cisco",
=======
   "id": "silent-balloon",
>>>>>>> 42938e1f0b653604946507663488f1cf44819e7d
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_test(model_path):\n",
    "    fast_model = loadEvalModel(model_path)\n",
    "    collapseCheck(fast_model, never_loader)\n",
    "    y_pre, y = validation(never_loader, fast_model, True)\n",
    "    sameDist, diffDist = calculateClusterDistClose_GPU(y_pre, y)\n",
    "    print('sameDist ', sameDist, ', diffDist ', diffDist, ', S/D ', sameDist / diffDist)\n",
    "    valList, farList, accList, accK = cal(y_pre, y)\n",
    "    showVAL_FAR_ACC(valList, farList, accList, accK)\n",
    "    y_pre, y = validation(never_loader, fast_model, False)\n",
    "    return y_pre, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "historic-retail",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"./model_V2_1024_fix_cross_triplet/checkpoint.pth.tar\"\n",
=======
   "id": "retired-tribune",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"./model_simCLR_oneLayer/checkpoint.pth.tar\"\n",
>>>>>>> 42938e1f0b653604946507663488f1cf44819e7d
    "y_pre_1, y_1 = auto_test(MODEL_PATH)\n",
    "auto_dimension_reduction(y_pre_1, y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "compound-statistics",
=======
   "id": "hybrid-valley",
>>>>>>> 42938e1f0b653604946507663488f1cf44819e7d
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "dramatic-rebate",
=======
   "id": "associate-ancient",
>>>>>>> 42938e1f0b653604946507663488f1cf44819e7d
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
